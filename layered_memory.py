# layered_memory.py
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
import json

class StructuredMemory(BaseModel):
    """é•¿æœŸè®°å¿†çš„ç»“æ„åŒ–æ•°æ®æ¨¡æ¿ï¼ˆè’¸é¦ç»“æœï¼‰"""
    entities: List[str] = Field(description="å¯¹è¯ä¸­æ¶‰åŠçš„æ ¸å¿ƒå®ä½“ï¼Œå¦‚æ–‡æ¡£ä¸­çš„æ¦‚å¿µã€æœ¯è¯­ã€äº§å“å")
    user_intents: List[str] = Field(description="ç”¨æˆ·çš„æ ¸å¿ƒæ„å›¾ï¼Œå¦‚è¯¢é—®å®šä¹‰ã€å¯¹æ¯”å·®å¼‚ã€æ±‚è§£é—®é¢˜")
    key_conclusions: List[str] = Field(description="å¯¹è¯ä¸­çš„æ ¸å¿ƒç»“è®º/æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯")
    context_ref: Dict[str, str] = Field(description="æŒ‡ä»£æ˜ å°„ï¼Œå¦‚'å®ƒ'â†’'æŸä¸ªæ¦‚å¿µ'")

    def to_dict(self) -> Dict:
        return {
            "entities": self.entities,
            "user_intents": self.user_intents,
            "key_conclusions": self.key_conclusions,
            "context_ref": self.context_ref
        }

    def to_prompt_text(self) -> str:
        return f"""
        å†å²å¯¹è¯æ ¸å¿ƒä¿¡æ¯ï¼š
        1. æ ¸å¿ƒå®ä½“ï¼š{', '.join(self.entities)}
        2. ç”¨æˆ·æ„å›¾ï¼š{', '.join(self.user_intents)}
        3. æ ¸å¿ƒç»“è®ºï¼š{', '.join(self.key_conclusions)}
        4. æŒ‡ä»£æ˜ å°„ï¼š{'; '.join([f'{k}â†’{v}' for k, v in self.context_ref.items()])}
        """

class LayeredMemoryManager:
    """åˆ†å±‚è®°å¿†ç®¡ç†å™¨ï¼šçŸ­æœŸè®°å¿†ï¼ˆåŸå§‹å¯¹è¯ï¼‰+ é•¿æœŸè®°å¿†ï¼ˆç»“æ„åŒ–è’¸é¦ï¼‰"""
    def __init__(self, llm, short_term_max_rounds: int = 3):
        self.short_term = ChatMessageHistory()  # æ¢å¤ä½¿ç”¨ChatMessageHistoryï¼Œæ›´è´´åˆåŸç”Ÿç”Ÿæ€
        self.short_term_max_rounds = short_term_max_rounds
        self.long_term: Optional[StructuredMemory] = None
        self.llm = llm
        self.distill_prompt = self._build_distill_prompt()

    def _build_distill_prompt(self) -> ChatPromptTemplate:
        """æ„å»ºè’¸é¦ç»“æ„åŒ–ä¿¡æ¯çš„Promptï¼ˆä¿®å¤{}è½¬ä¹‰é—®é¢˜ï¼‰"""
        return ChatPromptTemplate.from_messages([
            ("system", """è¯·ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–ç»“æ„åŒ–æ ¸å¿ƒä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼ˆä¸è¦é¢å¤–è§£é‡Šï¼Œä»…è¾“å‡ºJSONå­—ç¬¦ä¸²ï¼‰ï¼š
            1. entitiesï¼šä»…æå–æ–‡æ¡£ç›¸å…³çš„æ ¸å¿ƒå®ä½“/æœ¯è¯­ï¼Œä¸è¶…è¿‡5ä¸ª
            2. user_intentsï¼šä»…æå–ç”¨æˆ·çš„æ ¸å¿ƒæé—®æ„å›¾ï¼Œä¸è¶…è¿‡3ä¸ª
            3. key_conclusionsï¼šä»…æå–æ–‡æ¡£ä¸­çš„å…³é”®ç»“è®º/å›ç­”è¦ç‚¹ï¼Œä¸è¶…è¿‡3ä¸ª
            4. context_refï¼šæå–å¯¹è¯ä¸­çš„æ¨¡ç³ŠæŒ‡ä»£ï¼ˆå¦‚'å®ƒ'/'è¿™ä¸ª'ï¼‰ï¼Œæ˜ å°„åˆ°å…·ä½“å®ä½“
            ç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼ˆä»…ä½œå‚è€ƒï¼Œéœ€æ ¹æ®å®é™…å¯¹è¯ç”Ÿæˆï¼‰ï¼š
            {{{{
                "entities": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
                "user_intents": ["æ„å›¾1"],
                "key_conclusions": ["ç»“è®º1"],
                "context_ref": {{"å®ƒ": "æ¦‚å¿µ1"}}
            }}}}"""),  # å…³é”®ï¼šæ‰€æœ‰æ™®é€š{}è½¬ä¹‰ä¸º{{}}
            ("human", "å¯¹è¯å†…å®¹ï¼š{conversation_text}")  # è¿™é‡Œçš„{conversation_text}æ˜¯çœŸå®å˜é‡ï¼Œä¸è½¬ä¹‰
        ])

    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°çŸ­æœŸè®°å¿†ï¼Œå¹¶è§¦å‘è’¸é¦é€»è¾‘"""
        if role == "user":
            self.short_term.add_user_message(content)
        elif role == "assistant":
            self.short_term.add_ai_message(content)
        
        total_messages = len(self.short_term.messages)
        if total_messages >= 2 * self.short_term_max_rounds:
            self._distill_to_long_term()
            self.short_term.messages = self.short_term.messages[-2:]

    def _distill_to_long_term(self):
        """å°†çŸ­æœŸè®°å¿†è’¸é¦ä¸ºç»“æ„åŒ–ä¿¡æ¯ï¼Œå­˜å…¥é•¿æœŸè®°å¿†"""
        conversation_text = ""
        for msg in self.short_term.messages:
            role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "åŠ©æ‰‹"
            conversation_text += f"{role}ï¼š{msg.content}\n"
        
        try:
            chain = self.distill_prompt | self.llm | StrOutputParser()
            response = chain.invoke({"conversation_text": conversation_text})
            
            # è§£æå‰å…ˆæ¸…ç†å¯èƒ½çš„å¤šä½™å­—ç¬¦ï¼ˆå¦‚æ¢è¡Œã€ç©ºæ ¼ï¼‰
            distill_str = response.strip()
            # è‹¥è¾“å‡ºåŒ…å«ç¤ºä¾‹ä¸­çš„å¤–å±‚{{}}ï¼Œå…ˆå»é™¤ï¼ˆå¯é€‰ï¼Œå¢å¼ºå…¼å®¹æ€§ï¼‰
            if distill_str.startswith("{{") and distill_str.endswith("}}"):
                distill_str = distill_str[1:-1]  # å»é™¤é¦–å°¾å„ä¸€ä¸ªå¤§æ‹¬å·ï¼Œæ¢å¤ä¸º{}
            
            distill_data = json.loads(distill_str)
            new_struct_mem = StructuredMemory(**distill_data)
            
            if self.long_term is None:
                self.long_term = new_struct_mem
            else:
                self.long_term.entities = list(set(self.long_term.entities + new_struct_mem.entities))[:5]
                self.long_term.user_intents = list(set(self.long_term.user_intents + new_struct_mem.user_intents))[:3]
                self.long_term.key_conclusions = list(set(self.long_term.key_conclusions + new_struct_mem.key_conclusions))[:3]
                self.long_term.context_ref.update(new_struct_mem.context_ref)
            
            print(f"âœ… çŸ­æœŸè®°å¿†è’¸é¦å®Œæˆï¼Œé•¿æœŸè®°å¿†å·²æ›´æ–°")
            # ========== æ–°å¢ï¼šæ‰“å°é•¿æœŸè®°å¿†çš„ç»“æ„åŒ–å†…å®¹ ==========
            print(f"\nğŸ“‹ å½“å‰é•¿æœŸè®°å¿†ï¼ˆè’¸é¦åç»“æ„åŒ–å†…å®¹ï¼‰ï¼š")
            print(f"   æ ¸å¿ƒå®ä½“ï¼š{self.long_term.entities}")
            print(f"   ç”¨æˆ·æ„å›¾ï¼š{self.long_term.user_intents}")
            print(f"   æ ¸å¿ƒç»“è®ºï¼š{self.long_term.key_conclusions}")
            print(f"   æŒ‡ä»£æ˜ å°„ï¼š{self.long_term.context_ref}")
            # ==================================================
        except json.JSONDecodeError as e:
            print(f"âš ï¸ è’¸é¦ç»“æœJSONè§£æå¤±è´¥ï¼š{e}ï¼Œå“åº”å†…å®¹ï¼š{response}")
        except Exception as e:
            print(f"âš ï¸ è’¸é¦å¤±è´¥ï¼š{e}ï¼Œè·³è¿‡æœ¬æ¬¡è’¸é¦")

    def get_combined_memory(self) -> str:
        """è·å–ç»„åˆè®°å¿†ï¼šé•¿æœŸç»“æ„åŒ–è®°å¿† + çŸ­æœŸåŸå§‹è®°å¿†"""
        long_term_text = self.long_term.to_prompt_text() if self.long_term else ""
        
        short_term_text = "\næœ€æ–°å¯¹è¯ï¼š\n"
        for msg in self.short_term.messages:
            role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "åŠ©æ‰‹"
            short_term_text += f"{role}ï¼š{msg.content}\n"
        
        return long_term_text + short_term_text

    def clear_short_term(self):
        self.short_term.clear()
        print("ğŸ§¹ çŸ­æœŸè®°å¿†å·²æ¸…ç©º")

    def clear_long_term(self):
        self.long_term = None
        print("ğŸ§¹ é•¿æœŸè®°å¿†å·²æ¸…ç©º")

    def clear_all(self):
        self.clear_short_term()
        self.clear_long_term()
        return "ğŸ§¹ æ‰€æœ‰è®°å¿†å·²æ¸…ç©º"

    @property
    def short_term_messages(self):
        return self.short_term.messages